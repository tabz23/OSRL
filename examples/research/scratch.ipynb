{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001\n",
      "128\n",
      "adam\n",
      "{'learning_rate': 0.001, 'batch_size': 128, 'optimizer': 'adam'}\n",
      "0.001\n",
      "128\n",
      "adam\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass, asdict\n",
    "import types\n",
    "@dataclass\n",
    "class Config:\n",
    "    learning_rate: float = 0.001\n",
    "    batch_size: int = 128\n",
    "    optimizer: str = \"adam\"\n",
    "\n",
    "cfg = Config()\n",
    "print(cfg.learning_rate)  # Output: 0.001\n",
    "print(cfg.batch_size)     # Output: 128\n",
    "print(cfg.optimizer)      # Output: 'adam'\n",
    "\n",
    "cfg_dict = asdict(cfg)  # Convert the dataclass to a dictionary\n",
    "\n",
    "print(cfg_dict)\n",
    "# Output: {'learning_rate': 0.001, 'batch_size': 128, 'optimizer': 'adam'}\n",
    "# print(cfg_dict[\"learning_rate\"])  # Output: 0.001\n",
    "# print(cfg_dict[\"batch_size\"])     # Output: 128\n",
    "# print(cfg_dict[\"optimizer\"])      # Output: 'adam'\n",
    "\n",
    "args = types.SimpleNamespace(**cfg_dict)  # Convert dictionary to an object\n",
    "\n",
    "print(args.learning_rate)  # Output: 0.001\n",
    "print(args.batch_size)     # Output: 128\n",
    "print(args.optimizer)      # Output: 'adam'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epochs with batch size 32\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    print(f\"Training for {args.epochs} epochs with batch size {args.batch_size}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Create an ArgumentParser\n",
    "    parser = argparse.ArgumentParser(description=\"Training script\")\n",
    "    \n",
    "    # Step 2: Add arguments\n",
    "    parser.add_argument('--epochs', type=int, default=10, help=\"Number of training epochs\")\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help=\"Batch size for training\")\n",
    "\n",
    "\n",
    "    # args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()##because using jupyter\n",
    "\n",
    "    # Step 4: Pass parsed arguments to the main function\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 10 epochs with batch size 32\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "def main(args):\n",
    "    print(f\"Training for {args['epochs']} epochs with batch size {args['batch_size']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Create an ArgumentParser\n",
    "    parser = argparse.ArgumentParser(description=\"Training script\")\n",
    "    \n",
    "    # Step 2: Add arguments\n",
    "    parser.add_argument('--epochs', type=int, default=10, help=\"Number of training epochs\")\n",
    "    parser.add_argument('--batch_size', type=int, default=32, help=\"Batch size for training\")\n",
    "\n",
    "    # Step 3: Parse arguments and convert to dictionary\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    \n",
    "    args = vars(args)  # Convert Namespace to a dictionary\n",
    "\n",
    "    # Step 4: Pass parsed arguments to the main function\n",
    "    main(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: observations, Value: [1, 2, 3]\n",
      "Key: actions, Value: [0.1, 0.2, 0.3]\n",
      "Key: rewards, Value: [1, -1, 2]\n"
     ]
    }
   ],
   "source": [
    "dataset = {\n",
    "    \"observations\": [1, 2, 3],\n",
    "    \"actions\": [0.1, 0.2, 0.3],\n",
    "    \"rewards\": [1, -1, 2]\n",
    "}\n",
    "\n",
    "for k, v in dataset.items():\n",
    "    print(f\"Key: {k}, Value: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selcted transitions [0. 0. 1. 0. 1. 0.]\n",
      "Filtered Dataset:\n",
      "{'cost_returns': array([4.5, 5. ]), 'actions': array([0.3, 0.5])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "dataset = {\n",
    "    \"cost_returns\": np.array([1.5, 3.0, 4.5, 2.0, 5.0, 0.5]),  # Example cost returns\n",
    "    \"actions\": np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])       # Example actions\n",
    "}\n",
    "\n",
    "# Example cost limit\n",
    "cost_limit = 2.0\n",
    "\n",
    "# Initialize selected_transition as a binary array (e.g., all zeros initially)\n",
    "selected_transition = np.zeros_like(dataset[\"cost_returns\"])\n",
    "\n",
    "# Apply the condition to set values to 1 where cost returns >= 2 * cost_limit\n",
    "selected_transition[dataset[\"cost_returns\"] >= 2 * cost_limit] = 1\n",
    "print(\"selcted transitions\", selected_transition)\n",
    "# Now, filter dataset values based on selected_transition\n",
    "for k, v in dataset.items():\n",
    "    dataset[k] = v[selected_transition == 1]\n",
    "\n",
    "# Print the updated dataset\n",
    "print(\"Filtered Dataset:\")\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selcted transitions [False False  True False  True False]\n",
      "Filtered Dataset:\n",
      "{'cost_returns': array([4.5, 5. ]), 'actions': array([0.3, 0.5])}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example dataset\n",
    "dataset = {\n",
    "    \"cost_returns\": np.array([1.5, 3.0, 4.5, 2.0, 5.0, 0.5]),  # Example cost returns\n",
    "    \"actions\": np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6])       # Example actions\n",
    "}\n",
    "\n",
    "# Example cost limit\n",
    "cost_limit = 2.0\n",
    "\n",
    "# Initialize selected_transition as a binary array (e.g., all zeros initially)\n",
    "# selected_transition = np.zeros_like(dataset[\"cost_returns\"])\n",
    "\n",
    "# Apply the condition to set values to 1 where cost returns >= 2 * cost_limit\n",
    "selected_transition = dataset[\"cost_returns\"] >= 2 * cost_limit\n",
    "print(\"selcted transitions\", selected_transition)\n",
    "# Now, filter dataset values based on selected_transition\n",
    "for k, v in dataset.items():\n",
    "    dataset[k] = v[selected_transition]\n",
    "\n",
    "# Print the updated dataset\n",
    "print(\"Filtered Dataset:\")\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrallis\n",
    "\n",
    "# Define a class or function to be wrapped\n",
    "@pyrallis.wrap()\n",
    "class MyConfig:\n",
    "    batch_size: int\n",
    "    learning_rate: float\n",
    "    epochs: int\n",
    "\n",
    "# Function that uses the class wrapped by pyrallis\n",
    "def train_model(config: MyConfig):\n",
    "    print(f\"Batch Size: {config.batch_size}\")\n",
    "    print(f\"Learning Rate: {config.learning_rate}\")\n",
    "    print(f\"Epochs: {config.epochs}\")\n",
    "\n",
    "# Command to run the script\n",
    "# python script.py --batch_size 32 --learning_rate 0.001 --epochs 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log probabilities for each component of the action:\n",
      "tensor([-1.4189, -1.4189])\n",
      "\n",
      "Sum of log probabilities:\n",
      "tensor(-2.8379)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.distributions as dist\n",
    "\n",
    "# Let's say our action space is 2D (e.g., [x, y])\n",
    "# Create a 2D Normal distribution (mean=0, std=1) for each action component\n",
    "mu = torch.zeros(2)  # Mean of the distribution (2D)\n",
    "sigma = torch.ones(2)  # Standard deviation of the distribution (2D)\n",
    "pi = dist.Normal(mu, sigma)  # Define the distribution\n",
    "\n",
    "# Now, let's define a specific action [x, y]\n",
    "act = torch.tensor([1.0, -1.0])  # Example action\n",
    "\n",
    "# Compute the log probability of this action\n",
    "log_prob = pi.log_prob(act)  # This returns log probabilities for each dimension of the action\n",
    "\n",
    "print(\"Log probabilities for each component of the action:\")\n",
    "print(log_prob)  # It will show the log probabilities for each dimension of the action\n",
    "\n",
    "# Sum the log probabilities (this is often done when dealing with multivariate distributions)\n",
    "log_prob_sum = log_prob.sum()  # Sum along the last axis (for this 1D tensor, it's just the sum of the two components)\n",
    "print(\"\\nSum of log probabilities:\")\n",
    "print(log_prob_sum)  # This gives us a single scalar log probability value\n",
    "# log(p(a)*p(b)) = log(p(a))+log(p(B)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 5)\n",
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "my_range = range(5)\n",
    "print(my_range)\n",
    "my_list = list(my_range)\n",
    "print(my_list)  # Output: [0, 1, 2, 3, 4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[1], [2], [3]])  # Shape: (3, 1)\n",
    "print(x)\n",
    "x_expanded = x.expand(3, 1)\n",
    "x_repeated = x.repeat(1, 4)\n",
    "\n",
    "print(x_expanded)  # Memory-efficient, just changes view\n",
    "print(x_repeated)  # Actually copies data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "A = torch.randn(2, 3, 4)  # Shape (batch=2, 3, 4)\n",
    "B = torch.randn(2, 4, 5)  # Shape (batch=2, 4, 5)\n",
    "\n",
    "C = torch.bmm(A, B)  # (batch=2, 3, 5)\n",
    "print(C.shape)  # Output: torch.Size([2, 3, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original einsum shape: torch.Size([2, 3])\n",
      "New einsum shape: torch.Size([2, 3])\n",
      "\n",
      "Original einsum result:\n",
      " tensor([[0.6681, 0.4533, 0.5887],\n",
      "        [1.2167, 0.7889, 0.4954]])\n",
      "\n",
      "New einsum result:\n",
      " tensor([[0.6681, 0.4533, 0.5887],\n",
      "        [1.2167, 0.7889, 0.4954]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define dimensions\n",
    "batch_size = 2\n",
    "state_dim = 3\n",
    "num_action = 4\n",
    "\n",
    "# Create random tensors\n",
    "g = torch.rand(batch_size, state_dim, num_action)\n",
    "action = torch.rand(batch_size, num_action)\n",
    "\n",
    "# Perform both einsum operations\n",
    "gu_original = torch.einsum('bsa,ba->bs', g, action)\n",
    "gu_new = torch.einsum('bas,ba->bs', g.permute(0, 2, 1), action)\n",
    "\n",
    "# Print shapes and values\n",
    "print(\"Original einsum shape:\", gu_original.shape)\n",
    "print(\"New einsum shape:\", gu_new.shape)\n",
    "print(\"\\nOriginal einsum result:\\n\", gu_original)\n",
    "print(\"\\nNew einsum result:\\n\", gu_new)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 shape: torch.Size([2, 3, 5])\n",
      "Result 2 shape: torch.Size([2, 3, 5])\n",
      "\n",
      "Result 1 (first few elements):\n",
      "tensor([[7.1426, 6.6532, 5.6248],\n",
      "        [5.4513, 4.2430, 5.0380]])\n",
      "\n",
      "Result 2 (first few elements):\n",
      "tensor([[7.1426, 6.6532, 5.6248],\n",
      "        [5.4513, 4.2430, 5.0380]])\n",
      "\n",
      "Are results equal? True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define dimensions\n",
    "a, b, c, d, e = 2, 3, 4, 5, 6\n",
    "\n",
    "# Create random tensors\n",
    "x = torch.rand(a, b, c, d, e)\n",
    "y = torch.rand(a, c, e)\n",
    "\n",
    "# Original einsum\n",
    "result1 = torch.einsum('abcde,ace->abd', x, y)\n",
    "\n",
    "# Flipped order einsum\n",
    "result2 = torch.einsum('aedcb,ace->abd', x.permute(0, 4, 3, 2, 1), y)\n",
    "\n",
    "print(\"Result 1 shape:\", result1.shape)\n",
    "print(\"Result 2 shape:\", result2.shape)\n",
    "\n",
    "print(\"\\nResult 1 (first few elements):\")\n",
    "print(result1[:, :, 0])\n",
    "\n",
    "print(\"\\nResult 2 (first few elements):\")\n",
    "print(result2[:, :, 0])\n",
    "\n",
    "print(\"\\nAre results equal?\", torch.allclose(result1, result2, atol=1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(3*[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "param1: {'param1': 5, 'param2': 10, 'param3': 50, 'param4': 100, 'extra_param1': 500, 'extra_param2': 1000}\n",
      "param2: 0\n",
      "param3: 0\n",
      "param4: 0\n"
     ]
    }
   ],
   "source": [
    "class MyClass:\n",
    "    def __init__(self, param1=0, param2=0, param3=0, param4=0, **kwargs):\n",
    "        # Regular parameters\n",
    "        self.param1 = param1\n",
    "        self.param2 = param2\n",
    "        \n",
    "        # Default parameters\n",
    "        self.param3 = param3\n",
    "        self.param4 = param4\n",
    "        print(kwargs)\n",
    "\n",
    "        \n",
    "    def show_params(self):\n",
    "        print(f\"param1: {self.param1}\")\n",
    "        print(f\"param2: {self.param2}\")\n",
    "        print(f\"param3: {self.param3}\")\n",
    "        print(f\"param4: {self.param4}\")\n",
    "\n",
    "# Now, let's create a dictionary of parameters (args) and pass them to the class.\n",
    "args = {\n",
    "    \"param1\": 5, \n",
    "    \"param2\": 10, \n",
    "    \"param3\": 50,  # This overrides the default value for param3\n",
    "    \"param4\": 100, # This overrides the default value for param4\n",
    "    \"extra_param1\": 500,  # Extra parameter not defined in __init__()\n",
    "    \"extra_param2\": 1000  # Another extra parameter\n",
    "}\n",
    "\n",
    "# Unpack the args dictionary and pass them to MyClass\n",
    "obj = MyClass(**args)\n",
    "\n",
    "# Call the show_params method to see the parameters\n",
    "obj.show_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param1: 5\n",
      "param2: 10\n",
      "param3: 50\n"
     ]
    }
   ],
   "source": [
    "def example_function(param1, param2, param3=30):\n",
    "    print(f\"param1: {param1}\")\n",
    "    print(f\"param2: {param2}\")\n",
    "    print(f\"param3: {param3}\")\n",
    "\n",
    "# Dictionary with arguments\n",
    "args = {\n",
    "    \"param1\": 5, \n",
    "    \"param2\": 10, \n",
    "    \"param3\": 50  # This overrides the default value for param3\n",
    "}\n",
    "\n",
    "# Unpack the dictionary and pass as keyword arguments\n",
    "example_function(**args)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
